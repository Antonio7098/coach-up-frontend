# Sprint SPR-002 — Assessments v1

Implement Assessments v1: Convex data model, multi-turn assessment pipeline with rubric v1, and end-of-session summary generation + UI display.

## Meta
- Sprint ID: SPR-002
- Status: in progress
- Start date: 19/08/2025
- End date: <YYYY-MM-DD>
- Links: [Overview](./overview.md) · [PRD](../../planning/prd.md) · [Technical Overview](../../planning/technical-overview.md) · [Monitoring](../../ops/monitoring.md) · [Benchmarking](../../ops/benchmarking.md) · [Features CSV](../features.csv)

## Objectives (Tick when achieved)
- [ ] Assessment Data Model v1 in Convex with indexes
- [ ] Multi-turn assessment job (buffering + triggers)
- [ ] Rubric v1 implemented and versioned
- [ ] End-of-session summary generated and rendered in UI

## Planned Tasks
- [ ] Assessment Data Model — <owner> (<estimate>)
   - [ ] Schema, indexes, validation rules in Convex
   - [ ] Read/write functions + types
- [ ] Multi-turn Assessment Job — <owner> (<estimate>)
   - [ ] Trigger heuristics and grouping (groupId)
   - [ ] Background worker + batching
- [ ] Rubric v1 — <owner> (<estimate>)
   - [ ] Define categories, scoring buckets
   - [ ] Unit tests and golden cases
- [ ] Summary Generation & UI — <owner> (<estimate>)
   - [ ] Generate session summary document
   - [ ] Display in post-chat view

## Scope
In scope
- Per-interaction and multi-turn assessments
- Session summary generation and UI

Out of scope
- Advanced analytics and dashboards (SPR-005)
- Provider benchmarking (SPR-006)

## Features in this Sprint
List feature IDs from Features CSV (pipe-separate multiple)
- [ ] FEAT-010 — Assessment Data Model v1 (backend)
- [ ] FEAT-011 — Multi-turn Assessment Job v1 (ai)
- [ ] FEAT-008 — End-of-Session Summary v1 (ai)
- [ ] FEAT-009 — Summary Display UI (frontend)
- [ ] FEAT-028 — Rubric v1 for Assessments (ai)

## Acceptance Criteria
- [ ] Assessments are created with correct kind/category and validated
- [ ] Multi-turn assessments share a groupId and reference correct interactionIds
- [ ] Session summary is produced and visible in the UI

## Risks & Mitigations
- Risk: Over-triggering assessments · Mitigation: conservative heuristics + rate limits
- Risk: Rubric instability · Mitigation: lock rubric v1, add tests and versioning

## Dependencies
- Depends on features/sprints: SPR-001 (chat interactions exist)
- External: NA

## Technical Details
See design details in [Assessments v1 — Plan](../planning/assessments.md).
### Database Models
- Collections/Tables impacted: Assessment, Interaction, UserSession
- New/changed fields: Assessment.kind/category/score/errors/tags/groupId/rubricVersion
- Constraints/validation: kind/category combos; ids presence by kind; score ranges
- Indexes (read/write paths): Assessment by userId, sessionId, focusId, kind, createdAt, groupId
- Migrations: initial Assessment collection — Backfill plan: NA
- Data retention: Assessments retained; raw audio retention handled in storage sprint

### Algorithmic Details
- Approach: lightweight trigger → enqueue background analysis for multi-turn; per-interaction optional
- Rubric Version: v1
- Latency targets: Background completion p95 < 8s

### Prompts & Rubrics
- Prompt names/links: assessment-per-turn, assessment-multi-turn, summary
- Judge/rubric key points: correctness, clarity, minimality

## QA & Testing
- [ ] Unit tests for schema + job logic
- [ ] E2E: complete a scenario and see summary
- [ ] Load: batch 20 multi-turn assessments < 8s p95
- [ ] Contract tests between Next.js and FastAPI job endpoints

## Observability & SLOs
Targets (see Technical Overview §10)
- Realtime chat p95 TTFT < 1.2s; full-turn < 2.5s
- Assessment p95 completion < 8s

Checkpoints
- [ ] Dashboards include assessment latencies and error rates
- [ ] Alerts on backlog/timeout thresholds
- [ ] Structured logs include requestId, groupId, rubricVersion

## Issues & Deviations
Use this section to log issues encountered during the sprint, how they were resolved, and any deviations from the plan.

- Date: <YYYY-MM-DD> — Issue: <short summary> — Impact: <scope/users/services>
  - Detection: <alert/log/user report>
  - Fix: <what changed> — PR: <link> — Owner: <name>
  - Follow-up: <test/monitoring/doc action>
- Deviation from plan: <what changed and why>

## Operational Hygiene
- [ ] CI checks green (API Docs workflow, tests/linting)
- [ ] Branch protection respected (PR + review)
- [ ] Pre-commit hooks executed (lint/format/type checks)
- [ ] .env.example updated if new env vars added
- [ ] Request ID propagated end-to-end for changed paths
- [ ] Logs include: requestId, route, userId (if available), provider, modelId, tokens, cost, latency
- [ ] Rate limiting and idempotency considered for new/changed endpoints

## Documentation
Notes:
- Design doc: [Assessments v1 — Plan](../planning/assessments.md)
- [ ] API reference updated for endpoints touched (Core & AI)
- [ ] OpenAPI spec updated and linted
- [ ] Examples added/verified (curl + TypeScript)
- [ ] Cross-links updated (PRD/Technical Overview)

## Post-sprint
- [ ] KPIs reviewed; compare to targets
- [ ] Retrospective completed; action items filed

## Change Log
- 19/08/2025 Created sprint page; sprint started (in progress)
