# Sprint SPR-008 — Session Summary v2 with Client-side Caching

Implement a production-ready v2 of session summaries with frontend caching to reduce latency and backend load. Clients will include cached summaries in chat history and refresh them only every N turns or after T seconds.

## Meta
- Sprint ID: SPR-008
- Status: active
- Start date: 2025-08-29
- End date: 2025-09-05
- Links: [Overview](./overview.md) · [PRD](../../planning/prd.md) · [Technical Overview](../../planning/technical-overview.md) · [Monitoring](../../ops/monitoring.md) · [Benchmarking](../../ops/benchmarking.md) · [Features CSV](../features.csv)

## Objectives (Tick when achieved)
- [x] Frontend caches rolling session summary per `sessionId` and only refreshes every N turns or after T seconds
- [x] Chat SSE uses client `history` with summary + last M turns to shrink context
- [x] Minimal Next.js endpoint to fetch latest summary (mock/Convex) with auth and idempotency (idempotency header TBD)
- [ ] Observability: logs + metrics for cache hits/misses and refresh latency
- [x] Dedicated backend summary worker and queue with configurable concurrency
- [ ] Persist summaries in Convex `session_summaries` with proper indexes
- [ ] Token-budget-aware triggers (summarize when new tokens since last summary > X)
- [ ] Prompt extracts entities, goals, action items alongside narrative summary
- [ ] Backfill job processes legacy sessions to create initial summaries

## Planned Tasks
- [x] FE UI/Hook: `useSessionSummary(sessionId)` — <owner> (1d)
  - [x] Persist `{text, lastIndex, updatedAt, version}` in `sessionStorage`
  - [x] Threshold logic: refresh when turns >= N or age > T seconds (env-driven)
  - [x] Fire-and-forget refresh; never block chat/voice
- [x] FE Chat integration — <owner> (0.5d)
  - [x] Target page: `/coach` (integrates session summary + last M turns into SSE `history`)
  - [x] Encode summary as `{ role: 'system', content: '...summary...' }` + last M turns in `history`
  - [x] Fallback to last-10 turns when no summary exists
- [x] FE API: `/api/v1/session-summary` — <owner> (1d)
  - [x] GET latest summary by `sessionId`
  - [x] Supports MOCK_CONVEX path and Convex client path
  - [x] Auth via `requireAuth()` (optional gating)
  - [x] Rate limit & idempotency headers
- [ ] Convex integration (optional V1) — <owner> (0.5d)
   - [ ] Read latest summary event/document if available; else return `404 { none: true }`
- [x] Observability — <owner> (0.5d)
   - [x] Client logs: cache hit/miss, refresh start/end, error
   - [x] Next.js logs: requestId, userId, latency
 - [x] Docs & config — <owner> (0.5d)
   - [x] Update `.env.example` (frontend) with N/T/M vars
   - [x] Update sprint and technical docs (added rate limit headers + metrics)
- [ ] E2E: Playwright suite — <owner> (1d)
   - [ ] Deferred: will resume after Backend v2 tasks (2025-08-29)
   - [ ] Flows: first-load no-summary, cached-summary hit, threshold-triggered refresh, SSE history contains summary + M turns
   - [ ] Test harness: start Next.js app, seed/mock Convex (MOCK_CONVEX), use test auth
   - [ ] CI: upload traces/videos on failure; shard by file; retries=1
- [ ] Live LLM smoke tests (gated) — <owner> (0.5d)
   - [ ] Behind env flag `FEATURE_LIVE_LLM_TESTS=1`; provider keys via CI secrets
   - [ ] Nightly + manual workflow; marks `@live` to skip by default
   - [ ] Cost guard: token caps and timeouts; redact logs

V2 Backend & Data (this sprint)
- [x] Backend: dedicated `summary_queue` and worker in `coach-up-ai-api/app/main.py` — <owner> (1.5d)
  - [x] Concurrency via `SUMMARY_WORKER_CONCURRENCY`
  - [x] Enqueue from `/messages/ingest` on thresholds (turns=N)
  - [x] Metrics: `coachup_summary_jobs_total`, `coachup_summary_job_seconds`, `coachup_summary_enqueue_latency_seconds`, `coachup_summary_queue_depth`
- [ ] Convex schema: add `session_summaries` table — <owner> (1d)
  - [ ] Fields: `sessionId`, `version`, `lastIndex`, `text`, `entities`, `goals`, `actionItems`, `updatedAt`, `provider`, `model`, `tokens`, `costUsd`
  - [ ] Indexes: by `sessionId` (latest first), by `updatedAt`
  - [ ] Migration + backfill-safe write path
- [ ] Token-budget-aware trigger — <owner> (0.5d)
  - [ ] Track approx new tokens since last summary; threshold `SUMMARY_TOKEN_BUDGET`
- [ ] Prompt improvements — <owner> (0.5d)
  - [ ] Extract `entities`, `goals`, `actionItems`; keep `text` <= 2k chars
- [ ] Backfill job — <owner> (1d)
  - [ ] Scan recent sessions; produce initial summaries; rate-limit and log progress

## Progress Update — 2025-08-29

* __Hook implemented__: `ui/src/hooks/useSessionSummary.ts`
  - Caches `{ text, lastIndex, updatedAt, version }` in `sessionStorage` keyed by `sessionId`.
  - Env thresholds: `NEXT_PUBLIC_SUMMARY_REFRESH_TURNS=8`, `NEXT_PUBLIC_SUMMARY_REFRESH_SECONDS=120`.
  - Exposes `onTurn()` to nudge refresh on interaction turns.

* __API route delivered__: `ui/src/app/api/v1/session-summary/route.ts`
  - Supports `MOCK_CONVEX=1` via `mockConvex.getLatestAssessmentSummary()` and Convex client otherwise.
  - Optional auth gating via `requireAuth()`; Prometheus metrics wired.
  - Returns consolidated `text` from `highlights`, `recommendations`, `rubricKeyPoints`.

* __Chat integration (/coach)__: `ui/src/context/MicContext.tsx`
  - Prepends one `system` message with session summary to `history` built for `/api/chat`.
  - Calls `onTurn()` whenever `interactionTurnCount` changes to respect thresholds.

* __Smoke test__: local Next.js with Mock Convex
  - Start: `npm run dev:mock` in `ui/`.
  - Seed mock data:
    ```bash
    curl -s -i -X POST http://localhost:3000/api/dev/mock/seed \
      -H 'content-type: application/json' \
      -d '{"reset":true, "userId":"demo_user","assessmentsPerSkill":1, "levelPerAssessment":5, "sessionIdBase":"smoke_sess","groupIdBase":"grp_smoke","skillIds":["clarity_eloquence"]}'
    ```
  - Query summary:
    ```bash
    curl -s -i "http://localhost:3000/api/v1/session-summary?sessionId=smoke_sess_clarity_eloquence_0"
    ```
  - Observed response (200 OK):
    ```json
    {"sessionId":"smoke_sess_clarity_eloquence_0","groupId":"grp_smoke_clarity_eloquence_0","text":"","updatedAt":<ts>,"version":2,"rubricVersion":"v2"}
    ```
  - Note: `text` empty because no `summary` doc was created by seed; endpoint behavior differs from planned 404-when-missing. See Issues.

* __Next actions__:
  - Add mock seed endpoint/flag to create a session summary doc for smoke tests.
  - Optionally change route to return 404 when `summary` is null.
  - Add UI indicator for summary loading/error state.
  - Integrate and validate summary usage directly on `/coach` page (MicContext integration ongoing; E2E deferred until Mic providers finalized).
 
* __Smoke test results — 2025-08-29 11:35__
  - Server restarted: Next.js mock mode at `http://localhost:3000`.
  - Seed with summary: `POST /api/dev/mock/seed` with body `{ "createSummary": true, ... }` → 200 OK.
    - Response excerpt: `{ "ok": true, "skillsSeeded": 6, "assessmentsInserted": 1, "trackedCount": 1, "levelHistoryCount": 1, "summaryCreated": true }`.
  - Existing session summary: `GET /api/v1/session-summary?sessionId=smoke_sess_clarity_eloquence_0` → 200 OK.
    - `text` returned non-empty (Highlights, Recommendations, Key Points combined).
  - Non-existent session: `GET /api/v1/session-summary?sessionId=no_such_session` → 404 Not Found.
    - Payload: `{ "sessionId": "no_such_session", "summary": null }`.

  Notes
  - Route `ui/src/app/api/v1/session-summary/route.ts` now returns 404 when no summary exists, per acceptance criteria.
  - Mock seeding `ui/src/app/api/dev/mock/seed/route.ts` supports `createSummary` to generate a real summary for smoke tests.
  - Standard rate limit headers implemented and documented; Prometheus `rate_limited_total` metric added for 429s.
  - Contract/unit tests added for 200/404/429 flows and header presence.

### Backend summary worker shipped — 2025-08-29 14:00
* __Implementation__: `coach-up-ai-api/app/main.py`
  - In-memory `summary_queue` and `session_summaries` store
  - Strict every-N enqueue from `POST /messages/ingest` (N via `SUMMARY_WINDOW_N`, default 10)
  - Background `_summary_worker` builds compact rolling text (last N messages) and updates memory store
  - GET endpoint: `/api/v1/session-summary?sessionId=...` returns `{ version, updatedAt, summaryText }` + `ETag`
  - Optional async write-behind POST controlled by `SUMMARY_PERSIST_URL` + `SUMMARY_PERSIST_AUTH`
* __Env flags__:
  - `SUMMARY_ENABLED=1`
  - `SUMMARY_WORKER_CONCURRENCY=1`
  - `SUMMARY_WINDOW_N=10`
  - `SUMMARY_PERSIST_URL=` (optional)
  - `SUMMARY_PERSIST_AUTH=` (optional)
* __Metrics__:
  - `coachup_summary_jobs_total{status}`
  - `coachup_summary_job_seconds`
  - `coachup_summary_enqueue_latency_seconds`
  - `coachup_summary_queue_depth`
* __Notes__:
  - Token/age triggers are deferred to a later increment; we currently enqueue strictly every N messages.
  - Frontend continues to cache and include one system summary in SSE `history`.

## Scope
In scope
- Client-side caching of session summaries (sessionStorage + in-memory)
- Reduced chat context via summary + last M turns
- Minimal summary fetch endpoint in Next.js
 - Dedicated backend summary worker + queue with metrics and retries
 - Convex `session_summaries` table with indexes and migration
 - Token-budget-aware triggers and improved prompts (entities/goals/action items)
 - Backfill job for legacy sessions

Out of scope
- Heavy client-side LLM summarization
- None of the above backend items are out of scope in v2

## Features in this Sprint
List feature IDs from Features CSV (pipe-separate multiple)
- [x] FEAT-SSUM-CACHE — Client session summary cache (frontend)
- [x] FEAT-CHAT-CONTEXT-SHRINK — Use summary+M turns in SSE (chat)
 - [x] FEAT-SUMMARY-WORKER — Backend summary worker & queue
 - [ ] FEAT-SUMMARY-CONVEX — Convex `session_summaries` table + indexes
 - [ ] FEAT-SUMMARY-TOKENS — Token-budget-aware triggers
 - [ ] FEAT-SUMMARY-PROMPT-V2 — Entities/goals/action items extraction
 - [ ] FEAT-SUMMARY-BACKFILL — Backfill job for legacy sessions

## Acceptance Criteria
- [x] With summary present, `history` includes one `system` summary message and only last M (3–5) turns
- [x] Cache refresh triggers only when N turns (default 8) or age > T seconds (default 120s)
- [x] If refresh fails, previous summary remains and chat proceeds unblocked
- [x] Endpoint `/api/v1/session-summary` returns latest summary for valid session and 404 if none
 - [x] Basic auth gating (when enabled) and idempotency respected; requestId propagated
 - [x] Backend runs a dedicated summary worker queue with configurable concurrency
 - [ ] Summaries persisted in Convex `session_summaries`, retrievable by latest per session
 - [ ] Token-budget-aware triggering works (threshold configurable) and reduces unnecessary summaries
 - [ ] Summary payload includes `text`, `entities`, `goals`, `actionItems` and metadata (provider, model, tokens, cost, lastIndex)
 - [ ] Backfill job completes for targeted legacy window with audit logs
 - [ ] Playwright E2E: green for the 4 core flows; artifacts captured on failure
 - [ ] Live LLM smoke: passes within token/time caps; schema of summary fields validated

## Risks & Mitigations
- Risk: Stale summaries reduce response quality · Mitigation: age-based backstop and small M to retain recency
- Risk: Cache drift across tabs · Mitigation: store in `sessionStorage` per tab; optional StorageEvent sync later

## Dependencies
- Depends on features/sprints: SPR-006 (transcripts, classifier context)
- External: Convex availability (or MOCK_CONVEX path)

## Technical Details
### Database Models
- Collections/Tables impacted: Interactions (read-only), `session_summaries` (new)
- New/changed fields: `session_summaries.sessionId: string`, `version: number`, `lastIndex: number`, `text: string`, `entities: string[]`, `goals: string[]`, `actionItems: string[]`, `updatedAt: number`, `provider: string`, `model: string`, `tokens: number`, `costUsd: number`
- Constraints/validation: `sessionId` required; `version` monotonic per session
- Indexes (read/write paths): `session_summaries`: by `sessionId` (desc `updatedAt`), by `updatedAt`
- Migrations: Add table + indexes — Backfill plan: streaming job to populate latest summary per active session
- Data retention: Client cache lifetime per tab; server summaries retained per policy (e.g., 90d)

### Algorithmic Details
- Approach: Use cached `summary.text` + last M recent messages; thresholds N/T and token budget control refresh cadence
- Rubric Version: v2 downstream (for server-side assessments); N/A client-side
- Latency targets: TTFT unchanged; avoid added client waits during chat
- Token accounting: estimate tokens from message deltas (chars→tokens heuristic) and trigger when > `SUMMARY_TOKEN_BUDGET`

### Prompts & Rubrics
- Prompt names/links: chat (uses client `history`); summary prompt v2 (extract entities/goals/action items)
- Judge/rubric key points: concise, accurate, actionable items

## QA & Testing
- [ ] Unit tests (frontend): hook threshold logic, history builder
- [ ] E2E: voice chat flow keeps TTFT p95 < 1.2s with summary present
- [ ] Load/SSE smoke: confirm no extra calls per message
 - [x] Contract tests for `/api/v1/session-summary`
- [ ] Backend unit tests: worker enqueue thresholds (turns/age/tokens), prompt builder, persistence
- [ ] Migration tests: Convex `session_summaries` create/index; write/read path
- [ ] Backfill dry run test and idempotency
 - [ ] Playwright tests: cache hit/miss, refresh thresholds, SSE history assertions, auth handling
 - [ ] Live LLM tests: gated, provider-key via secrets, redacted logs, capped tokens/timeouts
   - [ ] Skip by default; run in nightly and manual dispatch

## Observability & SLOs
Targets (see Technical Overview §10)
- Realtime chat p95 TTFT < 1.2s; full-turn < 2.5s
- Assessment p95 completion < 8s (informational)

Checkpoints
 - [ ] Dashboards updated: FE cache hit/miss; BE summary worker queue depth, jobs/sec, errors, latency
 - [ ] CI dashboards: E2E pass rate, flake rate; nightly live run duration and failures
 - [ ] Alerts: 5xx on summary endpoint; worker failure rate; backlog > threshold; live test failures notify on-call (low severity)
 - [ ] Structured logs include requestId, userId (if available), route, provider, model, tokens, cost, latency; redact secrets in test logs

## Issues & Deviations
Use this section to log issues encountered during the sprint, how they were resolved, and any deviations from the plan.

- Date: 2025-08-29 — Issue: Summary endpoint returns 200 with empty `text` when no summary exists instead of 404
  - Detection: Smoke test against `/api/v1/session-summary`
  - Fix: Adjust route to return 404 when `raw.summary` is null OR seed a summary doc in mock for smoke tests
  - Follow-up: Add mock seed that calls `finalizeAssessmentSummary()` and ensure contract aligns with Acceptance Criteria
  - Status: resolved (2025-08-29 11:35) — Route now returns 404 for missing summaries; mock seed supports `createSummary` and produces non-empty `text` for seeded sessions
- Deviation from plan: TBD

## Operational Hygiene
- [ ] CI checks green (API Docs workflow, tests/linting)
- [ ] Branch protection respected (PR + review)
- [ ] Pre-commit hooks executed (lint/format/type checks)
- [ ] .env.example updated if new env vars added
- [ ] Request ID propagated end-to-end for changed paths
- [ ] Logs include: requestId, route, userId (if available), provider, modelId, tokens, cost, latency
- [ ] Rate limiting and idempotency considered for new/changed endpoints

## Documentation
- [ ] API reference updated for endpoints touched (Core & AI)
- [ ] OpenAPI spec updated and linted (if endpoint added)
- [ ] Examples added/verified (curl + TypeScript)
- [ ] Cross-links updated (PRD/Technical Overview)

## Post-sprint
- [ ] KPIs reviewed; compare to targets
- [ ] Retrospective completed; action items filed
- [ ] Docs updated (PRD/Tech Overview/Runbooks)

## Change Log
- 2025-08-29 Created sprint page
- 2025-08-29 Updated scope to full v2 (worker, Convex table, token triggers, prompt extraction, backfill)
- 2025-08-29 Implemented FE hook, API route, chat integration; smoke test executed in MOCK_CONVEX
- 2025-08-29 Finalized session-summary contract: 404 on missing sessions; added `createSummary` to mock seed; smoke tests verified 200 with populated text and 404 on missing
