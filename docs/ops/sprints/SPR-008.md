# Sprint SPR-008 — Session Summary v2 with Client-side Caching

Implement a production-ready v2 of session summaries with frontend caching to reduce latency and backend load. Clients will include cached summaries in chat history and refresh them only every N turns or after T seconds.

## Meta
- Sprint ID: SPR-008
- Status: active
- Start date: 2025-08-29
- End date: 2025-09-05
- Links: [Overview](./overview.md) · [PRD](../../planning/prd.md) · [Technical Overview](../../planning/technical-overview.md) · [Monitoring](../../ops/monitoring.md) · [Benchmarking](../../ops/benchmarking.md) · [Features CSV](../features.csv)

## Objectives (Tick when achieved)
- [ ] Frontend caches rolling session summary per `sessionId` and only refreshes every N turns or after T seconds
- [ ] Chat SSE uses client `history` with summary + last M turns to shrink context
- [ ] Minimal Next.js endpoint to fetch latest summary (mock/Convex) with auth and idempotency
- [ ] Observability: logs + metrics for cache hits/misses and refresh latency
- [ ] Dedicated backend summary worker and queue with configurable concurrency
- [ ] Persist summaries in Convex `session_summaries` with proper indexes
- [ ] Token-budget-aware triggers (summarize when new tokens since last summary > X)
- [ ] Prompt extracts entities, goals, action items alongside narrative summary
- [ ] Backfill job processes legacy sessions to create initial summaries

## Planned Tasks
- [ ] FE UI/Hook: `useSessionSummary(sessionId)` — <owner> (1d)
   - [ ] Persist `{text, lastIndex, updatedAt, version}` in `sessionStorage`
   - [ ] Threshold logic: refresh when turns >= N or age > T seconds (env-driven)
   - [ ] Fire-and-forget refresh; never block chat/voice
- [ ] FE Chat integration — <owner> (0.5d)
   - [ ] Encode summary as `{ role: 'system', content: 'Session summary: ...' }` + last M turns in `history`
   - [ ] Fallback to last-10 turns when no summary exists
- [ ] FE API: `/api/v1/session-summary` — <owner> (1d)
   - [ ] GET latest summary by `sessionId`
   - [ ] Supports MOCK_CONVEX path and Convex client path
   - [ ] Auth via `requireAuth()`; rate limit & idempotency headers
- [ ] Convex integration (optional V1) — <owner> (0.5d)
   - [ ] Read latest summary event/document if available; else return `404 { none: true }`
- [ ] Observability — <owner> (0.5d)
   - [ ] Client logs: cache hit/miss, refresh start/end, error
   - [ ] Next.js logs: requestId, userId, latency
- [ ] Docs & config — <owner> (0.5d)
   - [ ] Update `.env.example` (frontend) with N/T/M vars
   - [ ] Update sprint and technical docs
 - [ ] E2E: Playwright suite — <owner> (1d)
    - [ ] Flows: first-load no-summary, cached-summary hit, threshold-triggered refresh, SSE history contains summary + M turns
    - [ ] Test harness: start Next.js app, seed/mock Convex (MOCK_CONVEX), use test auth
    - [ ] CI: upload traces/videos on failure; shard by file; retries=1
 - [ ] Live LLM smoke tests (gated) — <owner> (0.5d)
    - [ ] Behind env flag `FEATURE_LIVE_LLM_TESTS=1`; provider keys via CI secrets
    - [ ] Nightly + manual workflow; marks `@live` to skip by default
    - [ ] Cost guard: token caps and timeouts; redact logs

V2 Backend & Data (this sprint)
- [ ] Backend: dedicated `summary_queue` and worker in `coach-up-ai-api/app/main.py` — <owner> (1.5d)
  - [ ] Concurrency via `SUMMARY_WORKER_CONCURRENCY`
  - [ ] Enqueue from `/messages/ingest` on thresholds (turns, age, tokens)
  - [ ] Metrics: `SESSION_SUMMARY_JOBS_TOTAL`, `SESSION_SUMMARY_SECONDS`, token/cost counters
- [ ] Convex schema: add `session_summaries` table — <owner> (1d)
  - [ ] Fields: `sessionId`, `version`, `lastIndex`, `text`, `entities`, `goals`, `actionItems`, `updatedAt`, `provider`, `model`, `tokens`, `costUsd`
  - [ ] Indexes: by `sessionId` (latest first), by `updatedAt`
  - [ ] Migration + backfill-safe write path
- [ ] Token-budget-aware trigger — <owner> (0.5d)
  - [ ] Track approx new tokens since last summary; threshold `SUMMARY_TOKEN_BUDGET`
- [ ] Prompt improvements — <owner> (0.5d)
  - [ ] Extract `entities`, `goals`, `actionItems`; keep `text` <= 2k chars
- [ ] Backfill job — <owner> (1d)
  - [ ] Scan recent sessions; produce initial summaries; rate-limit and log progress

## Scope
In scope
- Client-side caching of session summaries (sessionStorage + in-memory)
- Reduced chat context via summary + last M turns
- Minimal summary fetch endpoint in Next.js
 - Dedicated backend summary worker + queue with metrics and retries
 - Convex `session_summaries` table with indexes and migration
 - Token-budget-aware triggers and improved prompts (entities/goals/action items)
 - Backfill job for legacy sessions

Out of scope
- Heavy client-side LLM summarization
- None of the above backend items are out of scope in v2

## Features in this Sprint
List feature IDs from Features CSV (pipe-separate multiple)
- [ ] FEAT-SSUM-CACHE — Client session summary cache (frontend)
- [ ] FEAT-CHAT-CONTEXT-SHRINK — Use summary+M turns in SSE (chat)
 - [ ] FEAT-SUMMARY-WORKER — Backend summary worker & queue
 - [ ] FEAT-SUMMARY-CONVEX — Convex `session_summaries` table + indexes
 - [ ] FEAT-SUMMARY-TOKENS — Token-budget-aware triggers
 - [ ] FEAT-SUMMARY-PROMPT-V2 — Entities/goals/action items extraction
 - [ ] FEAT-SUMMARY-BACKFILL — Backfill job for legacy sessions

## Acceptance Criteria
- [ ] With summary present, `history` includes one `system` summary message and only last M (3–5) turns
- [ ] Cache refresh triggers only when N turns (default 8) or age > T seconds (default 120s)
- [ ] If refresh fails, previous summary remains and chat proceeds unblocked
- [ ] Endpoint `/api/v1/session-summary` returns latest summary for valid session and 404 if none
- [ ] Basic auth gating (when enabled) and idempotency respected; requestId propagated
 - [ ] Backend runs a dedicated summary worker queue with configurable concurrency
 - [ ] Summaries persisted in Convex `session_summaries`, retrievable by latest per session
 - [ ] Token-budget-aware triggering works (threshold configurable) and reduces unnecessary summaries
 - [ ] Summary payload includes `text`, `entities`, `goals`, `actionItems` and metadata (provider, model, tokens, cost, lastIndex)
 - [ ] Backfill job completes for targeted legacy window with audit logs
 - [ ] Playwright E2E: green for the 4 core flows; artifacts captured on failure
 - [ ] Live LLM smoke: passes within token/time caps; schema of summary fields validated

## Risks & Mitigations
- Risk: Stale summaries reduce response quality · Mitigation: age-based backstop and small M to retain recency
- Risk: Cache drift across tabs · Mitigation: store in `sessionStorage` per tab; optional StorageEvent sync later

## Dependencies
- Depends on features/sprints: SPR-006 (transcripts, classifier context)
- External: Convex availability (or MOCK_CONVEX path)

## Technical Details
### Database Models
- Collections/Tables impacted: Interactions (read-only), `session_summaries` (new)
- New/changed fields: `session_summaries.sessionId: string`, `version: number`, `lastIndex: number`, `text: string`, `entities: string[]`, `goals: string[]`, `actionItems: string[]`, `updatedAt: number`, `provider: string`, `model: string`, `tokens: number`, `costUsd: number`
- Constraints/validation: `sessionId` required; `version` monotonic per session
- Indexes (read/write paths): `session_summaries`: by `sessionId` (desc `updatedAt`), by `updatedAt`
- Migrations: Add table + indexes — Backfill plan: streaming job to populate latest summary per active session
- Data retention: Client cache lifetime per tab; server summaries retained per policy (e.g., 90d)

### Algorithmic Details
- Approach: Use cached `summary.text` + last M recent messages; thresholds N/T and token budget control refresh cadence
- Rubric Version: v2 downstream (for server-side assessments); N/A client-side
- Latency targets: TTFT unchanged; avoid added client waits during chat
- Token accounting: estimate tokens from message deltas (chars→tokens heuristic) and trigger when > `SUMMARY_TOKEN_BUDGET`

### Prompts & Rubrics
- Prompt names/links: chat (uses client `history`); summary prompt v2 (extract entities/goals/action items)
- Judge/rubric key points: concise, accurate, actionable items

## QA & Testing
- [ ] Unit tests (frontend): hook threshold logic, history builder
- [ ] E2E: voice chat flow keeps TTFT p95 < 1.2s with summary present
- [ ] Load/SSE smoke: confirm no extra calls per message
- [ ] Contract tests for `/api/v1/session-summary`
- [ ] Backend unit tests: worker enqueue thresholds (turns/age/tokens), prompt builder, persistence
- [ ] Migration tests: Convex `session_summaries` create/index; write/read path
- [ ] Backfill dry run test and idempotency
 - [ ] Playwright tests: cache hit/miss, refresh thresholds, SSE history assertions, auth handling
 - [ ] Live LLM tests: gated, provider-key via secrets, redacted logs, capped tokens/timeouts
   - [ ] Skip by default; run in nightly and manual dispatch

## Observability & SLOs
Targets (see Technical Overview §10)
- Realtime chat p95 TTFT < 1.2s; full-turn < 2.5s
- Assessment p95 completion < 8s (informational)

Checkpoints
 - [ ] Dashboards updated: FE cache hit/miss; BE summary worker queue depth, jobs/sec, errors, latency
 - [ ] CI dashboards: E2E pass rate, flake rate; nightly live run duration and failures
 - [ ] Alerts: 5xx on summary endpoint; worker failure rate; backlog > threshold; live test failures notify on-call (low severity)
 - [ ] Structured logs include requestId, userId (if available), route, provider, model, tokens, cost, latency; redact secrets in test logs

## Issues & Deviations
Use this section to log issues encountered during the sprint, how they were resolved, and any deviations from the plan.

- Date: 2025-08-29 — Issue: TBD — Impact: TBD
  - Detection: TBD
  - Fix: TBD — PR: TBD — Owner: TBD
  - Follow-up: TBD
- Deviation from plan: TBD

## Operational Hygiene
- [ ] CI checks green (API Docs workflow, tests/linting)
- [ ] Branch protection respected (PR + review)
- [ ] Pre-commit hooks executed (lint/format/type checks)
- [ ] .env.example updated if new env vars added
- [ ] Request ID propagated end-to-end for changed paths
- [ ] Logs include: requestId, route, userId (if available), provider, modelId, tokens, cost, latency
- [ ] Rate limiting and idempotency considered for new/changed endpoints

## Documentation
- [ ] API reference updated for endpoints touched (Core & AI)
- [ ] OpenAPI spec updated and linted (if endpoint added)
- [ ] Examples added/verified (curl + TypeScript)
- [ ] Cross-links updated (PRD/Technical Overview)

## Post-sprint
- [ ] KPIs reviewed; compare to targets
- [ ] Retrospective completed; action items filed
- [ ] Docs updated (PRD/Tech Overview/Runbooks)

## Change Log
- 2025-08-29 Created sprint page
 - 2025-08-29 Updated scope to full v2 (worker, Convex table, token triggers, prompt extraction, backfill)
