# Sprint SPR-006 — Session Transcript Persistence & Context Management

Persist session transcripts (independent of groupId) and pass the last N messages plus the system prompt to chat and classifier LLMs. Deliver thorough tests, monitoring, and docs.

## Meta
- Sprint ID: SPR-006
- Status: planned
- Start date: YYYY-MM-DD
- End date: YYYY-MM-DD
- Links: [Overview](./overview.md) · [PRD](../../planning/prd.md) · [Technical Overview](../../planning/technical-overview.md) · [Monitoring](../../ops/monitoring.md) · [Benchmarking](../../ops/benchmarking.md) · [Features CSV](../features.csv)

## Objectives (Tick when achieved)
- [ ] Persist session transcripts to DB independent of groupId, for both user and assistant messages.
- [ ] GroupId stored only as metadata on transcript items; context selection and ordering are by sessionId and timestamp only.
- [ ] Chat uses last `CHAT_CONTEXT_LIMIT` messages + system prompt for generation.
- [ ] Classifier uses last `CLASSIFIER_CONTEXT_LIMIT` messages + system prompt for boundary decisions.
- [ ] Privacy opt-out is configurable in Settings, persisted in DB, and respected (no transcript persistence when enabled).
- [ ] Complete coverage: unit, integration, e2e, smoke.
- [ ] Monitoring and docs updated.

## Planned Tasks
- [ ] Backend: persistence & ingestion — <owner> (3d)
  - [ ] Call [_persist_interaction_if_configured()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:786:0-815:12) from [messages_ingest](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:1741:0-2085:29) for user messages.
  - [ ] Add ingestion for assistant messages post-SSE (frontend posts) and persist when privacy opt-out is disabled.
  - [ ] Persist by `sessionId`; include optional `groupId` only as metadata on each transcript item; do not use `groupId` for chat/classifier context.
  - [ ] Respect privacy opt-out flag (per user/session) by skipping persistence and relying on in-memory transcript for runtime context.
- [ ] Backend: chat context — <owner> (2d)
  - [ ] Require `x-session-id` header; accept optional `x-group-id` header (metadata only; ignored for context windowing).
  - [ ] Build context via [_fetch_transcript_events_for_context(session_id, group_id, limit=CHAT_CONTEXT_LIMIT)](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:818:0-874:14), ignoring `groupId` for selection; order strictly by timestamp.
  - [ ] Inject system prompt and stream via provider client.
- [ ] Backend: classifier context — <owner> (2d)
  - [ ] Add `_classifier_context_limit_default()` and context slicing helper.
  - [ ] Use last M messages + system prompt when calling classifier.
  - [ ] Back-compat if provider doesn’t support message lists (compose an input string).
- [ ] Env & config — <owner> (0.5d)
  - [ ] Add [.env.example](cci:7://file:///home/antonio/programming/coach-up/coach-up-ai-api/.env.example:0:0-0:0) vars: `CHAT_CONTEXT_LIMIT`, `CLASSIFIER_CONTEXT_LIMIT`, `CHAT_CONTEXT_FROM_CONVEX`, `CHAT_SYSTEM_PROMPT`, `CLASSIFIER_SYSTEM_PROMPT`.
- [ ] Privacy & settings — <owner> (1d)
  - [ ] Add per-user or per-session `transcriptPersistenceOptOut` in Convex; expose in Settings UI.
  - [ ] Backend checks opt-out before persistence and during chat/classifier context building (fallback to in-memory when opted out).
- [ ] Observability — <owner> (1d)
  - [ ] Prometheus metrics for context sizes, persistence calls, Convex latency.
  - [ ] Grafana dashboards + alerts updates.
- [ ] QA & Testing — <owner> (2d)
  - [ ] Unit, integration (Convex mocked), 
  - [ ] e2e (Playwright), 
  - [ ] smoke (k6 for SSE).
  - [ ] End-to-end test with REAL LLM CALLS to verify REAL behavious. test the classifier in a range of scenarios (one-off, multi-turn scenario eg. role play, irellevant messages such as general chatter that is not asessable should not be enqueued). 
  - [ ] Contract tests for endpoints and ingestion ordering/idempotency.
- [ ] Documentation — <owner> (1d)
  - [ ] API Reference (chat stream headers, ingestion).
  - [ ] Technical Overview (context building, fallbacks).
  - [ ] Runbooks/Monitoring notes.
- [ ] CI — <owner> (0.5d)
  - [ ] Ensure new tests/linters wired; update workflows if needed.

## Scope
In scope
- Persisting all session interactions regardless of group state (sessionId primary key; groupId optional).
- groupId captured as metadata only; not used for context windowing for chat/classifier.
- Using last-N context windows for both chat and classifier.
- Enhancing [chat_stream()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:355:0-507:15) to fetch and pass context.
- Enhancing [messages_ingest](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:1741:0-2085:29) to persist and to classify with context.

Out of scope
- Changing assessment rubric logic or scoring.
- Audio persistence pipelines beyond URL pointer already supported.

## Features in this Sprint
- [ ] FEAT-CTX-001 — Persist session transcripts (backend)
- [ ] FEAT-CTX-002 — Chat context window (backend)
- [ ] FEAT-CTX-003 — Classifier context window (backend)
- [ ] FEAT-OBS-004 — Context observability dashboards (infra)

## Acceptance Criteria
- [ ] All messages (user, assistant) for a session are persisted even without a groupId.
- [ ] Chat generations use last `CHAT_CONTEXT_LIMIT` messages plus system prompt.
- [ ] Classifier calls use last `CLASSIFIER_CONTEXT_LIMIT` messages plus system prompt.
- [ ] Transcripts are fetched and ordered strictly by `sessionId` and timestamp (`ts`); groupId is metadata only and not used for chat/classifier context selection.
- [ ] Privacy opt-out can be toggled in Settings, is stored in DB, and disables transcript persistence while keeping runtime functionality via in-memory transcripts.
- [ ] End-to-end flow green in CI; smoke tests pass; dashboards show context metrics.

## Risks & Mitigations
- Risk: Provider interfaces differ (string vs messages). Mitigation: compose a single prompt from messages when message-list API is unavailable; keep a common adapter.
- Risk: Increased token/cost. Mitigation: clamp limits (1..200); add metrics and alerts; default sane values.
- Risk: Convex latency/error. Mitigation: fallback to in-memory via [_fetch_transcript_events_for_context](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:818:0-874:14); best-effort persistence (never fail user path).

## Dependencies
- Depends on: Convex interactions functions ([convex/functions/interactions.ts](cci:7://file:///home/antonio/programming/coach-up/coach-up-frontend/convex/functions/interactions.ts:0:0-0:0))
- External: Convex availability; provider APIs for chat/classifier

## Technical Details
### Database Models
- Collections: `interactions`
- Fields (already present in Convex): `sessionId`, `groupId`, `messageId`, `role`, `contentHash`, `text`, `audioUrl`, [ts](cci:7://file:///home/antonio/programming/coach-up/coach-up-frontend/convex/schema.ts:0:0-0:0), `createdAt`
- Indexes:
  - `interactions.by_session(sessionId)` (queries must order by `ts` ascending; take last-N by `ts` for context)
  - `interactions.by_group(groupId)` (for assessment agent use only)
- No schema changes required; ensure ingestion writes even when groupId is unknown (store session-only and fetch by session).
- Privacy:
  - Store per-user or per-session `transcriptPersistenceOptOut: boolean` in Convex (e.g., in Users or Sessions collection).
  - Backend ingestion skips persistence when true; runtime context falls back to in-memory transcript buffer.
- Data retention: governed by Convex defaults; align with 30d logs policy.

Implementation notes:
- [_persist_interaction_if_configured()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:786:0-815:12) should accept missing `groupId`; when provided, attach it as metadata only.
- For “independent of groupId”, persist user messages immediately with `sessionId` (use session list queries for context). Do not gate context on `groupId`.
- Respect privacy opt-out: if enabled, do not call persistence; still append to in-memory session transcript for runtime context. Assistant messages: persist post-SSE when not opted out (frontend calls ingestion with role=assistant).

### Algorithmic Details
- Context slicing:
  - Chat: [_fetch_transcript_events_for_context(session_id, group_id, limit)](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:818:0-874:14) returns events; ignore `groupId` for selection, order by `ts`, and take last N where N from [_chat_context_limit_default()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:745:0-758:12).
  - Classifier: add `_classifier_context_limit_default()` with same clamping (1..200); slice via the same fetcher.
- Chat system prompt:
  - Add env `CHAT_SYSTEM_PROMPT`; pass to provider as `system` when supported by [ChatClient.stream_chat(prompt, system)](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/providers/base.py:17:4-19:11).
  - Compose prompt from last-N events as `role: text` lines; include the user’s latest input.
- Classifier system prompt:
  - Add env `CLASSIFIER_SYSTEM_PROMPT`. Since [ClassifierClient.classify(role, content, turn_count, request_id)](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/providers/base.py:30:4-32:11) doesn’t accept messages, embed a brief context summary prefix (last M messages joined) into `content` before calling.
  - Optional future extension: add `messages` and `system` parameters to classifier clients.

### Prompts & Rubrics
- Prompts:
  - Chat system: `CHAT_SYSTEM_PROMPT` (concise instructions; coaching persona).
  - Classifier system: `CLASSIFIER_SYSTEM_PROMPT` (return one of start/continue/end/one_off plus confidence).
- Rubric: unchanged.

## QA & Testing
- Unit tests
  - [_chat_context_limit_default()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:745:0-758:12) and new `_classifier_context_limit_default()` clamping.
  - [_fetch_transcript_events_for_context()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:818:0-874:14) selection with and without `groupId`, Convex-on vs fallback.
  - Persist ingestion: user/assistant calls invoke [_persist_interaction_if_configured()](cci:1://file:///home/antonio/programming/coach-up/coach-up-ai-api/app/main.py:786:0-815:12) with correct args.
- Integration tests (mock Convex + providers)
  - Chat: `GET /chat/stream` with headers produces streams; logs contain provider/model; context size metric matches N.
  - Classifier: `POST /messages/ingest` triggers classify with context; updates state and spans as expected.
- E2E (Playwright)
  - Send multi-turn chat; verify last N messages are included (via deterministic mock provider echo of context size).
  - Verify “end” classification enqueues assessment and that results are available.
- Smoke (k6)
  - SSE stability: TTFT and total duration p95 thresholds; concurrent clients with short prompts.
- Contract tests
  - `POST /messages/ingest` idempotency (`messageId`) and ordering.
  - `GET /chat/stream` headers: `x-session-id`, `x-group-id` accepted.
- REAL LLM CALLS
  - End-to-end test with REAL LLM CALLS to verify REAL behavious. 
  - test the classifier in a range of scenarios (one-off, multi-turn scenario eg. role play, irellevant messages such as general chatter that is not asessable should not be enqueued).

## Observability & SLOs
Targets
- Realtime chat p95 TTFT < 1.2s; full-turn < 2.5s.
- Assessment p95 completion < 8s.

Checkpoints
- [ ] Dashboards updated:
  - Chat: TTFT, total, tokens (if available), `CHAT_CONTEXT_MESSAGES_COUNT`.
  - Classifier: decisions, confidence distribution, `CLASSIFIER_CONTEXT_MESSAGES_COUNT`.
  - Persistence: `PERSIST_INTERACTIONS_TOTAL`, Convex query/mutation latency.
  - Privacy: `PERSIST_SKIPPED_PRIVACY_TOTAL`.
- [ ] Alerts configured:
  - Elevated Convex latency/error rate.
  - TTFT/total latency regressions > thresholds.
- [ ] Logs include requestId, provider, model, context sizes, sessionId/groupId (hashed if needed), tokens, cost.

## Issues & Deviations
- Date: YYYY-MM-DD — Issue: <summary> — Impact: <scope>
  - Detection: <alert/log>
  - Fix: <what changed> — PR: <link> — Owner: <name>
  - Follow-up: <test/monitoring/doc action>

## Operational Hygiene
- [ ] CI checks green (API Docs, tests/lint).
- [ ] Branch protection observed.
- [ ] Pre-commit hooks (lint/format/type).
- [ ] [.env.example](cci:7://file:///home/antonio/programming/coach-up/coach-up-ai-api/.env.example:0:0-0:0) updated with new vars:
  - `CHAT_CONTEXT_LIMIT`, `CLASSIFIER_CONTEXT_LIMIT`, `CHAT_CONTEXT_FROM_CONVEX`.
  - `CHAT_SYSTEM_PROMPT`, `CLASSIFIER_SYSTEM_PROMPT`.
- [ ] Request ID propagated (chat stream + ingestion).
- [ ] Rate limiting and idempotency re-verified.

## Documentation
- [ ] API reference (AI) updated for:
  - `GET /chat/stream`: header `x-session-id` (required), `x-group-id` (optional metadata); context behavior; example.
  - `POST /messages/ingest`: role=`user|assistant`, idempotency, persistence behavior.
- [ ] OpenAPI spec updated and linted.
- [ ] Examples added (curl + TS).
- [ ] Technical Overview: context assembly diagram; Convex fallback.

## Post-sprint
- [ ] KPIs reviewed vs targets.
- [ ] Retro completed; action items filed.
- [ ] Runbooks updated (Convex outages; context caps).

## Change Log
- YYYY-MM-DD Created sprint page